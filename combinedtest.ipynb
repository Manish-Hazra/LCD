{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.nasnet import NASNetLarge\nfrom tensorflow.keras.applications.nasnet import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.models import Sequential\nimport numpy as np\nfrom glob import glob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mplimg\nfrom matplotlib.pyplot import imshow\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom skimage import color\nfrom skimage import io\nfrom skimage.transform import rescale, resize\nfrom keras import layers\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nimport keras.backend as K\nfrom keras.models import Sequential\nimport tensorflow as tf\nimport warnings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nf=[] \ndef listdirs(rootdir):\n    for file in os.listdir(rootdir):\n        d = os.path.join(rootdir, file)\n        if os.path.isdir(d):\n            print(d)\n            f.append(d)\n            listdirs(d)\n \nrootdir = '../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets'\nlistdirs(rootdir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom pathlib import Path\n\nimage_dir_path = '../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_n'\npaths = [path.parts[-3:] for path in\n         Path(image_dir_path).rglob('*.jpeg')]\ndf1 = pd.DataFrame(data=paths, columns=['Root', 'Type', 'Images'])\nprint(df1)\n\n\nimage_dir_path = '../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_scc'\npaths = [path.parts[-3:] for path in\n         Path(image_dir_path).rglob('*.jpeg')]\ndf2 = pd.DataFrame(data=paths, columns=['Root', 'Type', 'Images'])\nprint(df2)\nimage_dir_path ='../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_aca'\npaths = [path.parts[-3:] for path in\n         Path(image_dir_path).rglob('*.jpeg')]\ndf3 = pd.DataFrame(data=paths, columns=['Root', 'Type', 'Images'])\nprint(df3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df1,df2,df3])\ndf.reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.makedirs('/kaggle/working/cmyk/lung_n')\nos.makedirs('/kaggle/working/cmyk/lung_scc')\nos.makedirs('/kaggle/working/cmyk/lung_aca')\nos.makedirs('/kaggle/working/ycbcr/lung_n')\nos.makedirs('/kaggle/working/ycbcr/lung_scc')\nos.makedirs('/kaggle/working/ycbcr/lung_aca')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df.filter(['Type'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from zipfile import ZipFile\nfrom PIL import Image\nimport os\ndef prepareImages(data, m, dataset):\n    img_size=331\n    print(\"Preparing images\")\n    X_train = np.zeros((m, img_size, img_size, 1))\n    count = 0\n    p=0\n    for index,row in df.iterrows():\n        img = image.load_img(r\"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/\"+row[\"Type\"]+\"/\"+row[\"Images\"])\n        img_rgb = Image.open(r\"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/\"+row[\"Type\"]+\"/\"+row[\"Images\"])\n        img_cmyk = img_rgb.convert('CMYK')\n        img_ycbcr = img_rgb.convert('YCbCr')\n        img_cmyk.save(r\"./cmyk/\"+y['Type'].values[count]+\"/\"+\"processed\"+str(count)+\".jpeg\")\n        img_ycbcr.save(r\"./ycbcr/\"+y['Type'].values[count]+\"/\"+\"processed\"+str(count)+\".jpeg\")\n        count += 1\n        print(index)\n        print(row)\n        print(count)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prepareImages(df, df.shape[0], \"train\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (331, 331, 3)\n\ntrain_path_rgb = '../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets'\ntrain_path_cmyk = '../working/cmyk/'\ntrain_path_ycbcr = '..working/ycbcr/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folders = glob('../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/*')\nprint(len(folders))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nasnetL1 = NASNetLarge(input_shape=IMAGE_SIZE, include_top=False, weights=\"imagenet\")\nnasnetL2 = NASNetLarge(input_shape=IMAGE_SIZE, include_top=False, weights=\"imagenet\")\nnasnetL3 = NASNetLarge(input_shape=IMAGE_SIZE, include_top=False, weights=\"imagenet\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in nasnetL1.layers:\n    layer.trainable = False\nfor layer in nasnetL2.layers:\n    layer.trainable = False\nfor layer in nasnetL3.layers:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x1 = Flatten()(nasnetL1.output)\nx2 = Flatten()(nasnetL2.output)\nx3 = Flatten()(nasnetL3.output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction1 = Dense(len(folders), activation='softmax')(x1)\nprediction2 = Dense(len(folders), activation='softmax')(x2)\nprediction3 = Dense(len(folders), activation='softmax')(x3)\nmodel1 = Model(inputs=nasnetL1.input, outputs=prediction1)\nmodel2 = Model(inputs=nasnetL2.input, outputs=prediction2)\nmodel3 = Model(inputs=nasnetL3.input, outputs=prediction3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)\nmodel2.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)\nmodel3.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ndata1 = ImageDataGenerator(validation_split = 0.2,\n                          rescale = 1./224,\n                          shear_range = 0.2,\n                          zoom_range = 0.2,\n                          horizontal_flip = True)\ndata2 = ImageDataGenerator(validation_split = 0.2,\n                          rescale = 1./224,\n                          shear_range = 0.2,\n                          zoom_range = 0.2,\n                          horizontal_flip = True)\ndata3 = ImageDataGenerator(validation_split = 0.2,\n                          rescale = 1./224,\n                          shear_range = 0.2,\n                          zoom_range = 0.2,\n                          horizontal_flip = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set1 = data1.flow_from_directory(directory=r'../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/',\n                                                 target_size = (331, 331),\n                                                 batch_size = 64,\n                                                 subset = \"training\",\n                                                 class_mode = 'categorical')\ntraining_set2 = data2.flow_from_directory(directory=r'../working/cmyk/',\n                                                 target_size = (331, 331),\n                                                 batch_size = 64,\n                                                 subset = \"training\",\n                                                 class_mode = 'categorical')\ntraining_set3 = data3.flow_from_directory(directory=r'../working/ycbcr/',\n                                                 target_size = (331, 331),\n                                                 batch_size = 64,\n                                                 subset = \"training\",\n                                                 class_mode = 'categorical')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set1 = data1.flow_from_directory('../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/',\n                                            target_size = (331, 331),\n                                            batch_size = 64,\n                                            subset = \"validation\",\n                                            class_mode = 'categorical')\ntest_set2 = data2.flow_from_directory('../working/cmyk/',\n                                            target_size = (331, 331),\n                                            batch_size = 64,\n                                            subset = \"validation\",\n                                            class_mode = 'categorical')\ntest_set3 = data3.flow_from_directory('../working/ycbcr/',\n                                            target_size = (331, 331),\n                                            batch_size = 64,\n                                            subset = \"validation\",\n                                            class_mode = 'categorical')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r1 = model1.fit(\n  training_set1,\n  validation_data=test_set1,\n  epochs=20,\n  steps_per_epoch=len(training_set1),\n  validation_steps=len(test_set1)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r2 = model2.fit(\n  training_set2,\n  validation_data=test_set2,\n  epochs=20,\n  steps_per_epoch=len(training_set2),\n  validation_steps=len(test_set2)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r3 = model3.fit(\n  training_set3,\n  validation_data=test_set3,\n  epochs=20,\n  steps_per_epoch=len(training_set3),\n  validation_steps=len(test_set3)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_layerd1 = tf.keras.models.Model(\n    inputs=model1.inputs,\n    outputs=model1.get_layer(name=\"dense\").output,\n)\nfeatures_layerd2 = tf.keras.models.Model(\n    inputs=model2.inputs,\n    outputs=model2.get_layer(name=\"dense\").output,\n)\nfeatures_layerd3 = tf.keras.models.Model(\n    inputs=model3.inputs,\n    outputs=model3.get_layer(name=\"dense\").output,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_pred1=model1.get_layer(name=\"dense\").output\nfeature_pred2=model2.get_layer(name=\"dense\").output\nfeature_pred3=model3.get_layer(name=\"dense\").output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(40,5))\nplt.subplot(1, 5, 1)\nplt.title('RGB')\nplt.plot(r1.history['loss'], label='Train Loss')\nplt.plot(r1.history['val_loss'], label='Val Loss')\nplt.legend()\nplt.subplot(1, 5, 2)\nplt.title('CMYK')\nplt.plot(r2.history['loss'], label='Train Loss')\nplt.plot(r2.history['val_loss'], label='Val Loss')\nplt.legend()\nplt.subplot(1, 5, 3)\nplt.title('YCbCr')\nplt.plot(r3.history['loss'], label='Train Loss')\nplt.plot(r3.history['val_loss'], label='Val Loss')\nplt.legend()\nplt.show()\nplt.figure(figsize=(40,5))\nplt.subplot(1, 5, 1)\nplt.title('RGB')\nplt.plot(r1.history['accuracy'], label='Train Accuracy')\nplt.plot(r1.history['val_accuracy'], label='Val Accuracy')\nplt.legend()\nplt.subplot(1, 5, 2)\nplt.title('CMYK')\nplt.plot(r2.history['accuracy'], label='Train Accuracy')\nplt.plot(r2.history['val_accuracy'], label='Val Accuracy')\nplt.legend()\nplt.subplot(1, 5, 3)\nplt.title('YCbCr')\nplt.plot(r3.history['accuracy'], label='Train Accuracy')\nplt.plot(r3.history['val_accuracy'], label='Val Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel1.save('nasnetlargergb.h5')\nmodel2.save('nasnetlargecmyk.h5')\nmodel3.save('nasnetlargeycbcr.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred1 = model1.predict(test_set1)\ny_pred11 = np.argmax(y_pred1, axis=1)\ny_pred2 = model2.predict(test_set2)\ny_pred22 = np.argmax(y_pred2, axis=1)\ny_pred3 = model3.predict(test_set3)\ny_pred33 = np.argmax(y_pred3, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y1 = test_set1.classes\ny2 = test_set2.classes\ny3 = test_set3.classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yt1 = training_set1.classes\nyt2 = training_set2.classes\nyt3 = training_set3.classes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder(sparse=False)\ny1 = y1.reshape((3000, 1))\ny_r = encoder.fit_transform(y1)\n\nencoder = OneHotEncoder(sparse=False)\ny2 = y2.reshape((3000, 1))\ny_c = encoder.fit_transform(y2)\n\nencoder = OneHotEncoder(sparse=False)\ny3 = y3.reshape((3000, 1))\ny_y = encoder.fit_transform(y3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder(sparse=False)\nyt1 = yt1.reshape((12000, 1))\ny_tr = encoder.fit_transform(yt1)\n\nencoder = OneHotEncoder(sparse=False)\nyt2 = yt2.reshape((12000, 1))\ny_tc = encoder.fit_transform(yt2)\n\nencoder = OneHotEncoder(sparse=False)\nyt3 = yt3.reshape((12000, 1))\ny_ty = encoder.fit_transform(yt3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.concatenate((feature_pred1, feature_pred2, feature_pred3))\ny_train = np.concatenate((y_tr, y_tc, y_ty))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = np.concatenate((y_pred1, y_pred2, y_pred3))\ny_test = np.concatenate((y_r, y_c, y_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.concatenate((y_pred1, y_pred2, y_pred3))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import neighbors, datasets, preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, roc_curve, auc\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n\nknn = neighbors.KNeighborsClassifier(n_neighbors=2)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\n\nprint(accuracy_score(y_test, y_pred, normalize=False))\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean and Standard Deviation of training scores\nmean_training = np.mean(training_scores, axis=1)\nStandard_Deviation_training = np.std(training_scores, axis=1)\n  \n# Mean and Standard Deviation of testing scores\nmean_testing = np.mean(testing_scores, axis=1)\nStandard_Deviation_testing = np.std(testing_scores, axis=1)\n  \n# dotted blue line is for training scores and green line is for cross-validation score\nplt.plot(sizes, mean_training, '--', color=\"b\",  label=\"Training score\")\nplt.plot(sizes, mean_testing, color=\"g\", label=\"Cross-validation score\")\n  \n# Drawing plot\nplt.title(\"LEARNING CURVE FOR KNN Classifier\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr, tpr, threshold = roc_curve(y_test, y_pred[:, 1])\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC Curve of kNN')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=True,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, weight='bold', fontsize=16)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, fontsize=14)\n    plt.yticks(tick_marks, classes, fontsize=14)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\", fontsize=12, weight='bold',\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label', fontsize=16, weight='bold')\n    plt.xlabel('Predicted label', fontsize=16, weight='bold')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnf_matrix4 = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(40,5))\nplt.title('kNN')\nplot_confusion_matrix(cnf_matrix4, classes=['lung_aca', 'lung_n', 'lung_scc'],normalize=True,title='Normalized Confusion Matrix')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\nY_pred1 = model1.predict(test_set1)\ny_pred1 = np.argmax(Y_pred1, axis=1)\nprint(accuracy_score(test_set1.classes, y_pred1))\nprint(classification_report(test_set1.classes, y_pred1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nY_pred2 = model2.predict(test_set2)\ny_pred2 = np.argmax(Y_pred2, axis=1)\nprint(classification_report(test_set2.classes, y_pred2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nY_pred3 = model3.predict(test_set3)\ny_pred3 = np.argmax(Y_pred3, axis=1)\n\nprint(classification_report(test_set3.classes, y_pred3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=True,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, weight='bold', fontsize=16)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, fontsize=14)\n    plt.yticks(tick_marks, classes, fontsize=14)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\", fontsize=12, weight='bold',\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label', fontsize=16, weight='bold')\n    plt.xlabel('Predicted label', fontsize=16, weight='bold')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnf_matrix1 = confusion_matrix(test_set1.classes, y_pred1)\ncnf_matrix2 = confusion_matrix(test_set2.classes, y_pred2)\ncnf_matrix3 = confusion_matrix(test_set3.classes, y_pred3)\nnp.set_printoptions(precision=2)\nplt.figure(figsize=(40,5))\nplt.subplot(1,5,1)\nplt.title('RGB')\nplot_confusion_matrix(cnf_matrix1, classes=['lung_aca', 'lung_n', 'lung_scc'],normalize=True,title='Normalized Confusion Matrix')\nplt.subplot(1,5,2)\nplt.title('CMYK')\nplot_confusion_matrix(cnf_matrix2, classes=['lung_aca', 'lung_n', 'lung_scc'],normalize=True,title='Normalized Confusion Matrix')\nplt.subplot(1,5,3)\nplt.title('YCbCr')\nplot_confusion_matrix(cnf_matrix3, classes=['lung_aca', 'lung_n', 'lung_scc'],normalize=True,title='Normalized Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom IPython.display import Image, display\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = (299, 299)\n\nlast_conv_layer_name = \"normal_concat_18\"\nimg_rgb = \"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_n/lungn4125.jpeg\"\nimg_cmyk = \"../working/cmyk/lung_n/lungn3988.jpeg\"\nimg_ycbcr = \"../working/cmyk/lung_n/lungn3988.jpeg\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_array(img_path, size):\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    array = keras.preprocessing.image.img_to_array(img)\n    # of size (1, 299, 299, 3)\n    array = np.expand_dims(array, axis=0)\n    return array\n\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_rgb_array = preprocess_input(get_img_array(img_rgb, size=img_size))\nimg_cmyk_array = preprocess_input(get_img_array(img_cmyk, size=img_size))\nimg_ycbcr_array = preprocess_input(get_img_array(img_ycbcr, size=img_size))\n\n# Make model\nmodel_rgb = keras.model.load_model('nasnetlargergb.h5')\nmodel_cmyk = keras.model.load_model('nasnetlargecmyk.h5')\nmodel_ycbcr = keras.model.load_model('nasnetlargeycbcr.h5')\n\n\n# Remove last layer's softmax\nmodel_rgb.layers[-1].activation = None\nmodel_cmyk.layers[-1].activation = None\nmodel_ycbcr.layers[-1].activation = None\n\n# Print what the top predicted class is\npreds_rgb = model_rgb.predict(img_rgb_array)\npreds_cmyk = model_rgb.predict(img_cmyk_array)\npreds_ycbcr = model_rgb.predict(img_ycbcr_array)\nprint(\"Predicted:\", decode_predictions(preds_rgb, top=1)[0])\nprint(\"Predicted:\", decode_predictions(preds_cmyk, top=1)[0])\nprint(\"Predicted:\", decode_predictions(preds_ycbcr, top=1)[0])\nheatmap_rgb = make_gradcam_heatmap(img_rgb, model, last_conv_layer_name)\nplt.matshow(heatmap_rgb)\nheatmap_cmyk = make_gradcam_heatmap(img_cmyk, model, last_conv_layer_name)\nplt.matshow(heatmap_cmyk)\nheatmap_ycbcr = make_gradcam_heatmap(img_ycbcr, model, last_conv_layer_name)\nplt.matshow(heatmap_ycbcr)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n    img = keras.preprocessing.image.load_img(img_path)\n    img = keras.preprocessing.image.img_to_array(img)\n    heatmap = np.uint8(255 * heatmap)\n    jet = cm.get_cmap(\"jet\")\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n    superimposed_img.save(cam_path)\n    display(Image(cam_path))\n    \n\nsave_and_display_gradcam(img_rgb, heatmap_rgb)\nsave_and_display_gradcam(img_cmyk, heatmap_cmyk)\nsave_and_display_gradcam(img_ycbcr, heatmap_ycbcr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}