{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.nasnet import NASNetLarge\nfrom tensorflow.keras.applications.nasnet import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.models import Sequential\nimport numpy as np\nfrom glob import glob","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:10:41.751705Z","iopub.execute_input":"2023-02-14T07:10:41.752131Z","iopub.status.idle":"2023-02-14T07:10:52.262710Z","shell.execute_reply.started":"2023-02-14T07:10:41.752094Z","shell.execute_reply":"2023-02-14T07:10:52.261586Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mplimg\nfrom matplotlib.pyplot import imshow\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom skimage import color\nfrom skimage import io\nfrom skimage.transform import rescale, resize\nfrom keras import layers\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nimport keras.backend as K\nfrom keras.models import Sequential\nimport tensorflow as tf\nimport warnings","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:10:52.264861Z","iopub.execute_input":"2023-02-14T07:10:52.265506Z","iopub.status.idle":"2023-02-14T07:10:54.144671Z","shell.execute_reply.started":"2023-02-14T07:10:52.265474Z","shell.execute_reply":"2023-02-14T07:10:54.143622Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\nf=[] \ndef listdirs(rootdir):\n    for file in os.listdir(rootdir):\n        d = os.path.join(rootdir, file)\n        if os.path.isdir(d):\n            print(d)\n            f.append(d)\n            listdirs(d)\n \nrootdir = '../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets'\nlistdirs(rootdir)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:10:54.146070Z","iopub.execute_input":"2023-02-14T07:10:54.146433Z","iopub.status.idle":"2023-02-14T07:11:30.124773Z","shell.execute_reply.started":"2023-02-14T07:10:54.146397Z","shell.execute_reply":"2023-02-14T07:11:30.123581Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_aca\n../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_scc\n../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom pathlib import Path\n\nimage_dir_path = '../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_n'\npaths = [path.parts[-3:] for path in\n         Path(image_dir_path).rglob('*.jpeg')]\ndf1 = pd.DataFrame(data=paths, columns=['Root', 'Type', 'Images'])\nprint(df1)\n\n\nimage_dir_path = '../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_scc'\npaths = [path.parts[-3:] for path in\n         Path(image_dir_path).rglob('*.jpeg')]\ndf2 = pd.DataFrame(data=paths, columns=['Root', 'Type', 'Images'])\nprint(df2)\nimage_dir_path ='../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_aca'\npaths = [path.parts[-3:] for path in\n         Path(image_dir_path).rglob('*.jpeg')]\ndf3 = pd.DataFrame(data=paths, columns=['Root', 'Type', 'Images'])\nprint(df3)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:11:30.126301Z","iopub.execute_input":"2023-02-14T07:11:30.127033Z","iopub.status.idle":"2023-02-14T07:11:44.054922Z","shell.execute_reply.started":"2023-02-14T07:11:30.126987Z","shell.execute_reply":"2023-02-14T07:11:44.053769Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"                 Root    Type          Images\n0     lung_image_sets  lung_n   lungn691.jpeg\n1     lung_image_sets  lung_n  lungn3098.jpeg\n2     lung_image_sets  lung_n  lungn4225.jpeg\n3     lung_image_sets  lung_n    lungn40.jpeg\n4     lung_image_sets  lung_n  lungn4213.jpeg\n...               ...     ...             ...\n4995  lung_image_sets  lung_n  lungn1469.jpeg\n4996  lung_image_sets  lung_n  lungn1508.jpeg\n4997  lung_image_sets  lung_n  lungn1966.jpeg\n4998  lung_image_sets  lung_n  lungn4090.jpeg\n4999  lung_image_sets  lung_n   lungn554.jpeg\n\n[5000 rows x 3 columns]\n                 Root      Type            Images\n0     lung_image_sets  lung_scc  lungscc1930.jpeg\n1     lung_image_sets  lung_scc  lungscc1441.jpeg\n2     lung_image_sets  lung_scc  lungscc4624.jpeg\n3     lung_image_sets  lung_scc  lungscc4038.jpeg\n4     lung_image_sets  lung_scc  lungscc2504.jpeg\n...               ...       ...               ...\n4995  lung_image_sets  lung_scc  lungscc3958.jpeg\n4996  lung_image_sets  lung_scc   lungscc770.jpeg\n4997  lung_image_sets  lung_scc  lungscc4614.jpeg\n4998  lung_image_sets  lung_scc  lungscc3515.jpeg\n4999  lung_image_sets  lung_scc  lungscc1826.jpeg\n\n[5000 rows x 3 columns]\n                 Root      Type            Images\n0     lung_image_sets  lung_aca  lungaca2056.jpeg\n1     lung_image_sets  lung_aca  lungaca1914.jpeg\n2     lung_image_sets  lung_aca  lungaca3989.jpeg\n3     lung_image_sets  lung_aca  lungaca3803.jpeg\n4     lung_image_sets  lung_aca   lungaca861.jpeg\n...               ...       ...               ...\n4995  lung_image_sets  lung_aca  lungaca3823.jpeg\n4996  lung_image_sets  lung_aca  lungaca2457.jpeg\n4997  lung_image_sets  lung_aca  lungaca4147.jpeg\n4998  lung_image_sets  lung_aca  lungaca1477.jpeg\n4999  lung_image_sets  lung_aca  lungaca3216.jpeg\n\n[5000 rows x 3 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.concat([df1,df2,df3])\ndf.reset_index()","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:11:44.058212Z","iopub.execute_input":"2023-02-14T07:11:44.059251Z","iopub.status.idle":"2023-02-14T07:11:44.081436Z","shell.execute_reply.started":"2023-02-14T07:11:44.059213Z","shell.execute_reply":"2023-02-14T07:11:44.080469Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       index             Root      Type            Images\n0          0  lung_image_sets    lung_n     lungn691.jpeg\n1          1  lung_image_sets    lung_n    lungn3098.jpeg\n2          2  lung_image_sets    lung_n    lungn4225.jpeg\n3          3  lung_image_sets    lung_n      lungn40.jpeg\n4          4  lung_image_sets    lung_n    lungn4213.jpeg\n...      ...              ...       ...               ...\n14995   4995  lung_image_sets  lung_aca  lungaca3823.jpeg\n14996   4996  lung_image_sets  lung_aca  lungaca2457.jpeg\n14997   4997  lung_image_sets  lung_aca  lungaca4147.jpeg\n14998   4998  lung_image_sets  lung_aca  lungaca1477.jpeg\n14999   4999  lung_image_sets  lung_aca  lungaca3216.jpeg\n\n[15000 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Root</th>\n      <th>Type</th>\n      <th>Images</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>lung_image_sets</td>\n      <td>lung_n</td>\n      <td>lungn691.jpeg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>lung_image_sets</td>\n      <td>lung_n</td>\n      <td>lungn3098.jpeg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>lung_image_sets</td>\n      <td>lung_n</td>\n      <td>lungn4225.jpeg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>lung_image_sets</td>\n      <td>lung_n</td>\n      <td>lungn40.jpeg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>lung_image_sets</td>\n      <td>lung_n</td>\n      <td>lungn4213.jpeg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14995</th>\n      <td>4995</td>\n      <td>lung_image_sets</td>\n      <td>lung_aca</td>\n      <td>lungaca3823.jpeg</td>\n    </tr>\n    <tr>\n      <th>14996</th>\n      <td>4996</td>\n      <td>lung_image_sets</td>\n      <td>lung_aca</td>\n      <td>lungaca2457.jpeg</td>\n    </tr>\n    <tr>\n      <th>14997</th>\n      <td>4997</td>\n      <td>lung_image_sets</td>\n      <td>lung_aca</td>\n      <td>lungaca4147.jpeg</td>\n    </tr>\n    <tr>\n      <th>14998</th>\n      <td>4998</td>\n      <td>lung_image_sets</td>\n      <td>lung_aca</td>\n      <td>lungaca1477.jpeg</td>\n    </tr>\n    <tr>\n      <th>14999</th>\n      <td>4999</td>\n      <td>lung_image_sets</td>\n      <td>lung_aca</td>\n      <td>lungaca3216.jpeg</td>\n    </tr>\n  </tbody>\n</table>\n<p>15000 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import os\nos.makedirs('/kaggle/working/cmyk/lung_n')\nos.makedirs('/kaggle/working/cmyk/lung_scc')\nos.makedirs('/kaggle/working/cmyk/lung_aca')\nos.makedirs('/kaggle/working/ycbcr/lung_n')\nos.makedirs('/kaggle/working/ycbcr/lung_scc')\nos.makedirs('/kaggle/working/ycbcr/lung_aca')","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:11:44.082756Z","iopub.execute_input":"2023-02-14T07:11:44.083167Z","iopub.status.idle":"2023-02-14T07:11:44.090346Z","shell.execute_reply.started":"2023-02-14T07:11:44.083125Z","shell.execute_reply":"2023-02-14T07:11:44.089055Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"y = df.filter(['Type'])","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:11:44.091928Z","iopub.execute_input":"2023-02-14T07:11:44.092274Z","iopub.status.idle":"2023-02-14T07:11:44.108619Z","shell.execute_reply.started":"2023-02-14T07:11:44.092240Z","shell.execute_reply":"2023-02-14T07:11:44.107649Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:11:44.109839Z","iopub.execute_input":"2023-02-14T07:11:44.110137Z","iopub.status.idle":"2023-02-14T07:11:44.128483Z","shell.execute_reply.started":"2023-02-14T07:11:44.110096Z","shell.execute_reply":"2023-02-14T07:11:44.127402Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"          Type\n0       lung_n\n1       lung_n\n2       lung_n\n3       lung_n\n4       lung_n\n...        ...\n4995  lung_aca\n4996  lung_aca\n4997  lung_aca\n4998  lung_aca\n4999  lung_aca\n\n[15000 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>lung_n</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>lung_n</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>lung_n</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>lung_n</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>lung_n</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>lung_aca</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>lung_aca</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>lung_aca</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>lung_aca</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>lung_aca</td>\n    </tr>\n  </tbody>\n</table>\n<p>15000 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from zipfile import ZipFile\nfrom PIL import Image\nimport os\ndef prepareImages(data, m, dataset):\n    img_size=331\n    print(\"Preparing images\")\n    X_train = np.zeros((m, img_size, img_size, 1))\n    count = 0\n    p=0\n    for index,row in df.iterrows():\n        img = image.load_img(r\"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/\"+row[\"Type\"]+\"/\"+row[\"Images\"])\n        img_rgb = Image.open(r\"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/\"+row[\"Type\"]+\"/\"+row[\"Images\"])\n        img_cmyk = img_rgb.convert('CMYK')\n        img_ycbcr = img_rgb.convert('YCbCr')\n        img_cmyk.save(r\"./cmyk/\"+y['Type'].values[count]+\"/\"+\"processed\"+str(count)+\".jpeg\")\n        img_ycbcr.save(r\"./ycbcr/\"+y['Type'].values[count]+\"/\"+\"processed\"+str(count)+\".jpeg\")\n        count += 1\n        print(index)\n        print(row)\n        print(count)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:11:44.130110Z","iopub.execute_input":"2023-02-14T07:11:44.131141Z","iopub.status.idle":"2023-02-14T07:11:44.141740Z","shell.execute_reply.started":"2023-02-14T07:11:44.131104Z","shell.execute_reply":"2023-02-14T07:11:44.140765Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:11:44.143246Z","iopub.execute_input":"2023-02-14T07:11:44.144100Z","iopub.status.idle":"2023-02-14T07:11:44.160423Z","shell.execute_reply.started":"2023-02-14T07:11:44.144059Z","shell.execute_reply":"2023-02-14T07:11:44.159537Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"15000"},"metadata":{}}]},{"cell_type":"code","source":"prepareImages(df, df.shape[0], \"train\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (331, 331, 3)\n\ntrain_path_rgb = '../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets'\ntrain_path_cmyk = '../working/cmyk/'\ntrain_path_ycbcr = '..working/ycbcr/'","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:28:41.564493Z","iopub.execute_input":"2023-02-14T07:28:41.565235Z","iopub.status.idle":"2023-02-14T07:28:41.570730Z","shell.execute_reply.started":"2023-02-14T07:28:41.565191Z","shell.execute_reply":"2023-02-14T07:28:41.569741Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"folders = glob('../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/*')\nprint(len(folders))","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:28:41.572323Z","iopub.execute_input":"2023-02-14T07:28:41.573006Z","iopub.status.idle":"2023-02-14T07:28:41.598469Z","shell.execute_reply.started":"2023-02-14T07:28:41.572970Z","shell.execute_reply":"2023-02-14T07:28:41.597554Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"3\n","output_type":"stream"}]},{"cell_type":"code","source":"nasnetL1 = NASNetLarge(input_shape=IMAGE_SIZE, include_top=False, weights=\"imagenet\")\nnasnetL2 = NASNetLarge(input_shape=IMAGE_SIZE, include_top=False, weights=\"imagenet\")\nnasnetL3 = NASNetLarge(input_shape=IMAGE_SIZE, include_top=False, weights=\"imagenet\")","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:28:41.605241Z","iopub.execute_input":"2023-02-14T07:28:41.606762Z","iopub.status.idle":"2023-02-14T07:29:12.004920Z","shell.execute_reply.started":"2023-02-14T07:28:41.606728Z","shell.execute_reply":"2023-02-14T07:29:12.003829Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"2023-02-14 07:28:41.823591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:41.824541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:42.255997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:42.256993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:42.257834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:42.258660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:42.260700: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-02-14 07:28:42.518547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:42.519738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:42.521096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:42.522416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:42.523840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:42.524977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:46.878204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:46.879232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:46.880070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:46.880794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:46.881559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:46.882244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2023-02-14 07:28:46.893239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-14 07:28:46.893982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-large-no-top.h5\n343613440/343610240 [==============================] - 3s 0us/step\n343621632/343610240 [==============================] - 3s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"for layer in nasnetL1.layers:\n    layer.trainable = False\nfor layer in nasnetL2.layers:\n    layer.trainable = False\nfor layer in nasnetL3.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:29:12.006224Z","iopub.execute_input":"2023-02-14T07:29:12.006600Z","iopub.status.idle":"2023-02-14T07:29:12.098742Z","shell.execute_reply.started":"2023-02-14T07:29:12.006563Z","shell.execute_reply":"2023-02-14T07:29:12.097822Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"x1 = Flatten()(nasnetL1.output)\nx2 = Flatten()(nasnetL2.output)\nx3 = Flatten()(nasnetL3.output)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:29:12.100113Z","iopub.execute_input":"2023-02-14T07:29:12.101102Z","iopub.status.idle":"2023-02-14T07:29:12.117359Z","shell.execute_reply.started":"2023-02-14T07:29:12.101064Z","shell.execute_reply":"2023-02-14T07:29:12.116266Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"prediction1 = Dense(len(folders), activation='softmax')(x1)\nprediction2 = Dense(len(folders), activation='softmax')(x2)\nprediction3 = Dense(len(folders), activation='softmax')(x3)\nmodel1 = Model(inputs=nasnetL1.input, outputs=prediction1)\nmodel2 = Model(inputs=nasnetL2.input, outputs=prediction2)\nmodel3 = Model(inputs=nasnetL3.input, outputs=prediction3)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:29:12.118961Z","iopub.execute_input":"2023-02-14T07:29:12.119621Z","iopub.status.idle":"2023-02-14T07:29:12.333734Z","shell.execute_reply.started":"2023-02-14T07:29:12.119579Z","shell.execute_reply":"2023-02-14T07:29:12.332741Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model1.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)\nmodel2.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)\nmodel3.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:29:12.335122Z","iopub.execute_input":"2023-02-14T07:29:12.335707Z","iopub.status.idle":"2023-02-14T07:29:12.396559Z","shell.execute_reply.started":"2023-02-14T07:29:12.335670Z","shell.execute_reply":"2023-02-14T07:29:12.395669Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ndata1 = ImageDataGenerator(validation_split = 0.2,\n                          rescale = 1./224,\n                          shear_range = 0.2,\n                          zoom_range = 0.2,\n                          horizontal_flip = True)\ndata2 = ImageDataGenerator(validation_split = 0.2,\n                          rescale = 1./224,\n                          shear_range = 0.2,\n                          zoom_range = 0.2,\n                          horizontal_flip = True)\ndata3 = ImageDataGenerator(validation_split = 0.2,\n                          rescale = 1./224,\n                          shear_range = 0.2,\n                          zoom_range = 0.2,\n                          horizontal_flip = True)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:29:12.397908Z","iopub.execute_input":"2023-02-14T07:29:12.398369Z","iopub.status.idle":"2023-02-14T07:29:12.406005Z","shell.execute_reply.started":"2023-02-14T07:29:12.398330Z","shell.execute_reply":"2023-02-14T07:29:12.404961Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"training_set1 = data1.flow_from_directory(directory=r'../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/',\n                                                 target_size = (331, 331),\n                                                 batch_size = 64,\n                                                 subset = \"training\",\n                                                 class_mode = 'categorical')\ntraining_set2 = data2.flow_from_directory(directory=r'../working/cmyk/',\n                                                 target_size = (331, 331),\n                                                 batch_size = 64,\n                                                 subset = \"training\",\n                                                 class_mode = 'categorical')\ntraining_set3 = data3.flow_from_directory(directory=r'../working/ycbcr/',\n                                                 target_size = (331, 331),\n                                                 batch_size = 64,\n                                                 subset = \"training\",\n                                                 class_mode = 'categorical')","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:29:12.407541Z","iopub.execute_input":"2023-02-14T07:29:12.408220Z","iopub.status.idle":"2023-02-14T07:29:19.859611Z","shell.execute_reply.started":"2023-02-14T07:29:12.408184Z","shell.execute_reply":"2023-02-14T07:29:19.858496Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Found 12000 images belonging to 3 classes.\nFound 12000 images belonging to 3 classes.\nFound 12000 images belonging to 3 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_set1 = data1.flow_from_directory('../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/',\n                                            target_size = (331, 331),\n                                            batch_size = 64,\n                                            subset = \"validation\",\n                                            class_mode = 'categorical')\ntest_set2 = data2.flow_from_directory('../working/cmyk/',\n                                            target_size = (331, 331),\n                                            batch_size = 64,\n                                            subset = \"validation\",\n                                            class_mode = 'categorical')\ntest_set3 = data3.flow_from_directory('../working/ycbcr/',\n                                            target_size = (331, 331),\n                                            batch_size = 64,\n                                            subset = \"validation\",\n                                            class_mode = 'categorical')","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:29:19.861288Z","iopub.execute_input":"2023-02-14T07:29:19.862160Z","iopub.status.idle":"2023-02-14T07:29:20.604441Z","shell.execute_reply.started":"2023-02-14T07:29:19.862119Z","shell.execute_reply":"2023-02-14T07:29:20.603429Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Found 3000 images belonging to 3 classes.\nFound 3000 images belonging to 3 classes.\nFound 3000 images belonging to 3 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"r1 = model1.fit(\n  training_set1,\n  validation_data=test_set1,\n  epochs=5,\n  steps_per_epoch=len(training_set1),\n  validation_steps=len(test_set1)\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T07:29:20.605558Z","iopub.execute_input":"2023-02-14T07:29:20.605927Z","iopub.status.idle":"2023-02-14T08:26:52.347962Z","shell.execute_reply.started":"2023-02-14T07:29:20.605894Z","shell.execute_reply":"2023-02-14T08:26:52.346749Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"2023-02-14 07:29:22.898158: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"2023-02-14 07:29:42.962043: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"188/188 [==============================] - 724s 4s/step - loss: 1.9819 - accuracy: 0.9087 - val_loss: 1.1702 - val_accuracy: 0.9437\nEpoch 2/5\n188/188 [==============================] - 680s 4s/step - loss: 1.2527 - accuracy: 0.9448 - val_loss: 1.2230 - val_accuracy: 0.9523\nEpoch 3/5\n188/188 [==============================] - 681s 4s/step - loss: 0.9210 - accuracy: 0.9643 - val_loss: 1.4527 - val_accuracy: 0.9537\nEpoch 4/5\n188/188 [==============================] - 680s 4s/step - loss: 1.0149 - accuracy: 0.9639 - val_loss: 0.8428 - val_accuracy: 0.9723\nEpoch 5/5\n188/188 [==============================] - 677s 4s/step - loss: 0.7853 - accuracy: 0.9712 - val_loss: 1.0987 - val_accuracy: 0.9663\n","output_type":"stream"}]},{"cell_type":"code","source":"r2 = model2.fit(\n  training_set2,\n  validation_data=test_set2,\n  epochs=5,\n  steps_per_epoch=len(training_set2),\n  validation_steps=len(test_set2)\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-14T08:26:52.350975Z","iopub.execute_input":"2023-02-14T08:26:52.351794Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/5\n188/188 [==============================] - 765s 4s/step - loss: 1.7688 - accuracy: 0.9112 - val_loss: 1.4469 - val_accuracy: 0.9287\nEpoch 2/5\n188/188 [==============================] - 735s 4s/step - loss: 1.2719 - accuracy: 0.9460 - val_loss: 1.9615 - val_accuracy: 0.9333\nEpoch 3/5\n188/188 [==============================] - 727s 4s/step - loss: 1.3123 - accuracy: 0.9557 - val_loss: 1.0452 - val_accuracy: 0.9643\nEpoch 4/5\n188/188 [==============================] - 724s 4s/step - loss: 0.9580 - accuracy: 0.9635 - val_loss: 1.2373 - val_accuracy: 0.9590\nEpoch 5/5\n182/188 [============================>.] - ETA: 18s - loss: 0.8521 - accuracy: 0.9703","output_type":"stream"}]},{"cell_type":"code","source":"r3 = model3.fit(\n  training_set3,\n  validation_data=test_set3,\n  epochs=5,\n  steps_per_epoch=len(training_set3),\n  validation_steps=len(test_set3)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(40,5))\nplt.subplot(1, 5, 1)\nplt.title('RGB')\nplt.plot(r1.history['loss'], label='Train Loss')\nplt.plot(r1.history['val_loss'], label='Val Loss')\nplt.legend()\nplt.subplot(1, 5, 2)\nplt.title('CMYK')\nplt.plot(r2.history['loss'], label='Train Loss')\nplt.plot(r2.history['val_loss'], label='Val Loss')\nplt.legend()\nplt.subplot(1, 5, 3)\nplt.title('YCbCr')\nplt.plot(r3.history['loss'], label='Train Loss')\nplt.plot(r3.history['val_loss'], label='Val Loss')\nplt.legend()\nplt.show()\nplt.figure(figsize=(40,5))\nplt.subplot(1, 5, 1)\nplt.title('RGB')\nplt.plot(r1.history['accuracy'], label='Train Accuracy')\nplt.plot(r1.history['val_accuracy'], label='Val Accuracy')\nplt.legend()\nplt.subplot(1, 5, 2)\nplt.title('CMYK')\nplt.plot(r2.history['accuracy'], label='Train Accuracy')\nplt.plot(r2.history['val_accuracy'], label='Val Accuracy')\nplt.legend()\nplt.subplot(1, 5, 3)\nplt.title('YCbCr')\nplt.plot(r3.history['accuracy'], label='Train Accuracy')\nplt.plot(r3.history['val_accuracy'], label='Val Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel1.save('nasnetlargergb.h5')\nmodel2.save('nasnetlargecmyk.h5')\nmodel3.save('nasnetlargeycbcr.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred1 = model1.predict(test_set1)\ny_pred11 = np.argmax(y_pred1, axis=1)\ny_pred2 = model2.predict(test_set2)\ny_pred22 = np.argmax(y_pred2, axis=1)\ny_pred3 = model3.predict(test_set3)\ny_pred33 = np.argmax(y_pred3, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y1 = test_set1.classes\ny2 = test_set2.classes\ny3 = test_set3.classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder(sparse=False)\ny1 = y1.reshape((3000, 1))\ny_r = encoder.fit_transform(y1)\n\nencoder = OneHotEncoder(sparse=False)\ny2 = y2.reshape((3000, 1))\ny_c = encoder.fit_transform(y2)\n\nencoder = OneHotEncoder(sparse=False)\ny3 = y3.reshape((3000, 1))\ny_y = encoder.fit_transform(y3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = np.concatenate((y_pred1, y_pred2, y_pred3))\ny_label = np.concatenate((y_r, y_c, y_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import neighbors, datasets, preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, roc_curve, auc\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\nXtrain, Xtest, y_tr, y_test = train_test_split(y_train, y_label, stratify = y_label, random_state = 0, train_size = 0.7)\nprint(y_tr.shape, y_test.shape)\n\n\nknn = neighbors.KNeighborsClassifier(n_neighbors=1)\nknn.fit(Xtrain, y_tr)\ny_pred = knn.predict(Xtest)\n\nprint(accuracy_score(y_test, y_pred, normalize=False))\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import learning_curve\n  \nXtrain, Xtest, y_tr, y_test = train_test_split(y_train, y_label, stratify = y_label, random_state = 0, train_size = 0.7)\n  \n# Obtain scores from learning curve function\n# cv is the number of folds while performing Cross Validation\nsizes, training_scores, testing_scores = learning_curve(KNeighborsClassifier(), Xtrain, y_tr, cv=10, scoring='accuracy', train_sizes=np.linspace(0.01, 1.0, 50))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean and Standard Deviation of training scores\nmean_training = np.mean(training_scores, axis=1)\nStandard_Deviation_training = np.std(training_scores, axis=1)\n  \n# Mean and Standard Deviation of testing scores\nmean_testing = np.mean(testing_scores, axis=1)\nStandard_Deviation_testing = np.std(testing_scores, axis=1)\n  \n# dotted blue line is for training scores and green line is for cross-validation score\nplt.plot(sizes, mean_training, '--', color=\"b\",  label=\"Training score\")\nplt.plot(sizes, mean_testing, color=\"g\", label=\"Cross-validation score\")\n  \n# Drawing plot\nplt.title(\"LEARNING CURVE FOR KNN Classifier\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr, tpr, threshold = roc_curve(y_test, y_pred[:, 1])\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC Curve of kNN')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=True,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, weight='bold', fontsize=16)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, fontsize=14)\n    plt.yticks(tick_marks, classes, fontsize=14)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\", fontsize=12, weight='bold',\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label', fontsize=16, weight='bold')\n    plt.xlabel('Predicted label', fontsize=16, weight='bold')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnf_matrix4 = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(40,5))\nplt.title('kNN')\nplot_confusion_matrix(cnf_matrix4, classes=['lung_aca', 'lung_n', 'lung_scc'],normalize=True,title='Normalized Confusion Matrix')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\nY_pred1 = model1.predict(test_set1)\ny_pred1 = np.argmax(Y_pred1, axis=1)\nprint(accuracy_score(test_set1.classes, y_pred1))\nprint(classification_report(test_set1.classes, y_pred1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nY_pred2 = model2.predict(test_set2)\ny_pred2 = np.argmax(Y_pred2, axis=1)\nprint(classification_report(test_set2.classes, y_pred2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nY_pred3 = model3.predict(test_set3)\ny_pred3 = np.argmax(Y_pred3, axis=1)\n\nprint(classification_report(test_set3.classes, y_pred3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=True,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, weight='bold', fontsize=16)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, fontsize=14)\n    plt.yticks(tick_marks, classes, fontsize=14)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\", fontsize=12, weight='bold',\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label', fontsize=16, weight='bold')\n    plt.xlabel('Predicted label', fontsize=16, weight='bold')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnf_matrix1 = confusion_matrix(test_set1.classes, y_pred1)\ncnf_matrix2 = confusion_matrix(test_set2.classes, y_pred2)\ncnf_matrix3 = confusion_matrix(test_set3.classes, y_pred3)\nnp.set_printoptions(precision=2)\nplt.figure(figsize=(40,5))\nplt.subplot(1,5,1)\nplt.title('RGB')\nplot_confusion_matrix(cnf_matrix1, classes=['lung_aca', 'lung_n', 'lung_scc'],normalize=True,title='Normalized Confusion Matrix')\nplt.subplot(1,5,2)\nplt.title('CMYK')\nplot_confusion_matrix(cnf_matrix2, classes=['lung_aca', 'lung_n', 'lung_scc'],normalize=True,title='Normalized Confusion Matrix')\nplt.subplot(1,5,3)\nplt.title('YCbCr')\nplot_confusion_matrix(cnf_matrix3, classes=['lung_aca', 'lung_n', 'lung_scc'],normalize=True,title='Normalized Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom IPython.display import Image, display\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = (299, 299)\n\nlast_conv_layer_name = \"normal_concat_18\"\nimg_rgb = \"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_n/lungn4125.jpeg\"\nimg_cmyk = \"../working/cmyk/lung_n/lungn3988.jpeg\"\nimg_ycbcr = \"../working/cmyk/lung_n/lungn3988.jpeg\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_array(img_path, size):\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    array = keras.preprocessing.image.img_to_array(img)\n    # of size (1, 299, 299, 3)\n    array = np.expand_dims(array, axis=0)\n    return array\n\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_rgb_array = preprocess_input(get_img_array(img_rgb, size=img_size))\nimg_cmyk_array = preprocess_input(get_img_array(img_cmyk, size=img_size))\nimg_ycbcr_array = preprocess_input(get_img_array(img_ycbcr, size=img_size))\n\n# Make model\nmodel_rgb = keras.model.load_model('nasnetlargergb.h5')\nmodel_cmyk = keras.model.load_model('nasnetlargecmyk.h5')\nmodel_ycbcr = keras.model.load_model('nasnetlargeycbcr.h5')\n\n\n# Remove last layer's softmax\nmodel_rgb.layers[-1].activation = None\nmodel_cmyk.layers[-1].activation = None\nmodel_ycbcr.layers[-1].activation = None\n\n# Print what the top predicted class is\npreds_rgb = model_rgb.predict(img_rgb_array)\npreds_cmyk = model_rgb.predict(img_cmyk_array)\npreds_ycbcr = model_rgb.predict(img_ycbcr_array)\nprint(\"Predicted:\", decode_predictions(preds_rgb, top=1)[0])\nprint(\"Predicted:\", decode_predictions(preds_cmyk, top=1)[0])\nprint(\"Predicted:\", decode_predictions(preds_ycbcr, top=1)[0])\nheatmap_rgb = make_gradcam_heatmap(img_rgb, model, last_conv_layer_name)\nplt.matshow(heatmap_rgb)\nheatmap_cmyk = make_gradcam_heatmap(img_cmyk, model, last_conv_layer_name)\nplt.matshow(heatmap_cmyk)\nheatmap_ycbcr = make_gradcam_heatmap(img_ycbcr, model, last_conv_layer_name)\nplt.matshow(heatmap_ycbcr)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n    img = keras.preprocessing.image.load_img(img_path)\n    img = keras.preprocessing.image.img_to_array(img)\n    heatmap = np.uint8(255 * heatmap)\n    jet = cm.get_cmap(\"jet\")\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n    superimposed_img.save(cam_path)\n    display(Image(cam_path))\n    \n\nsave_and_display_gradcam(img_rgb, heatmap_rgb)\nsave_and_display_gradcam(img_cmyk, heatmap_cmyk)\nsave_and_display_gradcam(img_ycbcr, heatmap_ycbcr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}