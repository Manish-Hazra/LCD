{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.nasnet import NASNetLarge\nfrom tensorflow.keras.applications.nasnet import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.models import Sequential\nimport numpy as np\nfrom glob import glob","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:29:26.255566Z","iopub.execute_input":"2023-02-01T05:29:26.256205Z","iopub.status.idle":"2023-02-01T05:29:32.627883Z","shell.execute_reply.started":"2023-02-01T05:29:26.256085Z","shell.execute_reply":"2023-02-01T05:29:32.626792Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mplimg\nfrom matplotlib.pyplot import imshow\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom skimage import color\nfrom skimage import io\nfrom skimage.transform import rescale, resize\nfrom keras import layers\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nimport keras.backend as K\nfrom keras.models import Sequential\nimport tensorflow as tf\nimport warnings","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:29:37.094850Z","iopub.execute_input":"2023-02-01T05:29:37.095651Z","iopub.status.idle":"2023-02-01T05:29:38.080098Z","shell.execute_reply.started":"2023-02-01T05:29:37.095612Z","shell.execute_reply":"2023-02-01T05:29:38.078978Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nf=[] \ndef listdirs(rootdir):\n    for file in os.listdir(rootdir):\n        d = os.path.join(rootdir, file)\n        if os.path.isdir(d):\n            print(d)\n            f.append(d)\n            listdirs(d)\n \nrootdir = '../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets'\nlistdirs(rootdir)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:29:53.741348Z","iopub.execute_input":"2023-02-01T05:29:53.741730Z","iopub.status.idle":"2023-02-01T05:30:01.705454Z","shell.execute_reply.started":"2023-02-01T05:29:53.741688Z","shell.execute_reply":"2023-02-01T05:30:01.704294Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_aca\n../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_scc\n../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom pathlib import Path\n\nimage_dir_path = '../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_n'\npaths = [path.parts[-3:] for path in\n         Path(image_dir_path).rglob('*.jpeg')]\ndf1 = pd.DataFrame(data=paths, columns=['Root', 'Type', 'Images'])\nprint(df1)\n\n\nimage_dir_path = '../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_scc'\npaths = [path.parts[-3:] for path in\n         Path(image_dir_path).rglob('*.jpeg')]\ndf2 = pd.DataFrame(data=paths, columns=['Root', 'Type', 'Images'])\nprint(df2)\nimage_dir_path ='../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_aca'\npaths = [path.parts[-3:] for path in\n         Path(image_dir_path).rglob('*.jpeg')]\ndf3 = pd.DataFrame(data=paths, columns=['Root', 'Type', 'Images'])\nprint(df3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df1,df2,df3])\ndf.reset_index()","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:30:31.349261Z","iopub.execute_input":"2023-02-01T05:30:31.349812Z","iopub.status.idle":"2023-02-01T05:30:31.380074Z","shell.execute_reply.started":"2023-02-01T05:30:31.349769Z","shell.execute_reply":"2023-02-01T05:30:31.378955Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       index             Root      Type            Images\n0          0  lung_image_sets    lung_n     lungn691.jpeg\n1          1  lung_image_sets    lung_n    lungn3098.jpeg\n2          2  lung_image_sets    lung_n    lungn4225.jpeg\n3          3  lung_image_sets    lung_n      lungn40.jpeg\n4          4  lung_image_sets    lung_n    lungn4213.jpeg\n...      ...              ...       ...               ...\n14995   4995  lung_image_sets  lung_aca  lungaca3823.jpeg\n14996   4996  lung_image_sets  lung_aca  lungaca2457.jpeg\n14997   4997  lung_image_sets  lung_aca  lungaca4147.jpeg\n14998   4998  lung_image_sets  lung_aca  lungaca1477.jpeg\n14999   4999  lung_image_sets  lung_aca  lungaca3216.jpeg\n\n[15000 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Root</th>\n      <th>Type</th>\n      <th>Images</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>lung_image_sets</td>\n      <td>lung_n</td>\n      <td>lungn691.jpeg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>lung_image_sets</td>\n      <td>lung_n</td>\n      <td>lungn3098.jpeg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>lung_image_sets</td>\n      <td>lung_n</td>\n      <td>lungn4225.jpeg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>lung_image_sets</td>\n      <td>lung_n</td>\n      <td>lungn40.jpeg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>lung_image_sets</td>\n      <td>lung_n</td>\n      <td>lungn4213.jpeg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14995</th>\n      <td>4995</td>\n      <td>lung_image_sets</td>\n      <td>lung_aca</td>\n      <td>lungaca3823.jpeg</td>\n    </tr>\n    <tr>\n      <th>14996</th>\n      <td>4996</td>\n      <td>lung_image_sets</td>\n      <td>lung_aca</td>\n      <td>lungaca2457.jpeg</td>\n    </tr>\n    <tr>\n      <th>14997</th>\n      <td>4997</td>\n      <td>lung_image_sets</td>\n      <td>lung_aca</td>\n      <td>lungaca4147.jpeg</td>\n    </tr>\n    <tr>\n      <th>14998</th>\n      <td>4998</td>\n      <td>lung_image_sets</td>\n      <td>lung_aca</td>\n      <td>lungaca1477.jpeg</td>\n    </tr>\n    <tr>\n      <th>14999</th>\n      <td>4999</td>\n      <td>lung_image_sets</td>\n      <td>lung_aca</td>\n      <td>lungaca3216.jpeg</td>\n    </tr>\n  </tbody>\n</table>\n<p>15000 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import os\nos.makedirs('/kaggle/working/cmyk/lung_n')\nos.makedirs('/kaggle/working/cmyk/lung_scc')\nos.makedirs('/kaggle/working/cmyk/lung_aca')\nos.makedirs('/kaggle/working/ycbcr/lung_n')\nos.makedirs('/kaggle/working/ycbcr/lung_scc')\nos.makedirs('/kaggle/working/ycbcr/lung_aca')","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:30:39.199538Z","iopub.execute_input":"2023-02-01T05:30:39.199972Z","iopub.status.idle":"2023-02-01T05:30:39.207878Z","shell.execute_reply.started":"2023-02-01T05:30:39.199935Z","shell.execute_reply":"2023-02-01T05:30:39.206627Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"y = df.filter(['Type'])","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:30:45.374307Z","iopub.execute_input":"2023-02-01T05:30:45.374730Z","iopub.status.idle":"2023-02-01T05:30:45.386179Z","shell.execute_reply.started":"2023-02-01T05:30:45.374664Z","shell.execute_reply":"2023-02-01T05:30:45.384932Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:30:50.027940Z","iopub.execute_input":"2023-02-01T05:30:50.028322Z","iopub.status.idle":"2023-02-01T05:30:50.041233Z","shell.execute_reply.started":"2023-02-01T05:30:50.028288Z","shell.execute_reply":"2023-02-01T05:30:50.039939Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"          Type\n0       lung_n\n1       lung_n\n2       lung_n\n3       lung_n\n4       lung_n\n...        ...\n4995  lung_aca\n4996  lung_aca\n4997  lung_aca\n4998  lung_aca\n4999  lung_aca\n\n[15000 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>lung_n</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>lung_n</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>lung_n</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>lung_n</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>lung_n</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>lung_aca</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>lung_aca</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>lung_aca</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>lung_aca</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>lung_aca</td>\n    </tr>\n  </tbody>\n</table>\n<p>15000 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from zipfile import ZipFile\nfrom PIL import Image\nimport os\ndef prepareImages(data, m, dataset):\n    img_size=331\n    print(\"Preparing images\")\n    X_train = np.zeros((m, img_size, img_size, 1))\n    count = 0\n    p=0\n    for index,row in df.iterrows():\n        img = image.load_img(r\"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/\"+row[\"Type\"]+\"/\"+row[\"Images\"])\n        img_rgb = Image.open(r\"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/\"+row[\"Type\"]+\"/\"+row[\"Images\"])\n        img_cmyk = img_rgb.convert('CMYK')\n        img_ycbcr = img_rgb.convert('YCbCr')\n        img_cmyk.save(r\"./cmyk/\"+y['Type'].values[count]+\"/\"+\"processed\"+str(count)+\".jpeg\")\n        img_ycbcr.save(r\"./ycbcr/\"+y['Type'].values[count]+\"/\"+\"processed\"+str(count)+\".jpeg\")\n        count += 1\n        print(index)\n        print(row)\n        print(count)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:30:58.740114Z","iopub.execute_input":"2023-02-01T05:30:58.740508Z","iopub.status.idle":"2023-02-01T05:30:58.748748Z","shell.execute_reply.started":"2023-02-01T05:30:58.740475Z","shell.execute_reply":"2023-02-01T05:30:58.747636Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:31:03.824630Z","iopub.execute_input":"2023-02-01T05:31:03.825053Z","iopub.status.idle":"2023-02-01T05:31:03.832095Z","shell.execute_reply.started":"2023-02-01T05:31:03.825021Z","shell.execute_reply":"2023-02-01T05:31:03.830723Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"15000"},"metadata":{}}]},{"cell_type":"code","source":"prepareImages(df, df.shape[0], \"train\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (331, 331, 3)\n\ntrain_path_rgb = '../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets'\ntrain_path_cmyk = '../working/cmyk/'\ntrain_path_ycbcr = '..working/ycbcr/'","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:48:13.988286Z","iopub.execute_input":"2023-02-01T05:48:13.988699Z","iopub.status.idle":"2023-02-01T05:48:13.994406Z","shell.execute_reply.started":"2023-02-01T05:48:13.988638Z","shell.execute_reply":"2023-02-01T05:48:13.993174Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"folders = glob('../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/*')\nprint(len(folders))","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:48:18.423520Z","iopub.execute_input":"2023-02-01T05:48:18.424301Z","iopub.status.idle":"2023-02-01T05:48:18.431794Z","shell.execute_reply.started":"2023-02-01T05:48:18.424262Z","shell.execute_reply":"2023-02-01T05:48:18.430655Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"3\n","output_type":"stream"}]},{"cell_type":"code","source":"nasnetL1 = NASNetLarge(input_shape=IMAGE_SIZE, include_top=False, weights=\"imagenet\")\nnasnetL2 = NASNetLarge(input_shape=IMAGE_SIZE, include_top=False, weights=\"imagenet\")\nnasnetL3 = NASNetLarge(input_shape=IMAGE_SIZE, include_top=False, weights=\"imagenet\")","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:48:22.352476Z","iopub.execute_input":"2023-02-01T05:48:22.352885Z","iopub.status.idle":"2023-02-01T05:48:53.912170Z","shell.execute_reply.started":"2023-02-01T05:48:22.352849Z","shell.execute_reply":"2023-02-01T05:48:53.911086Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"2023-02-01 05:48:22.559061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:22.560360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:22.763171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:22.764429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:22.765382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:22.766307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:22.768552: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-02-01 05:48:23.064822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:23.065931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:23.066887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:23.067738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:23.068549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:23.069603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:26.178087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:26.179183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:26.180123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:26.181005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:26.182002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:26.183038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2023-02-01 05:48:26.186511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-01 05:48:26.187362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-large-no-top.h5\n343613440/343610240 [==============================] - 2s 0us/step\n343621632/343610240 [==============================] - 2s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"for layer in nasnetL1.layers:\n    layer.trainable = False\nfor layer in nasnetL2.layers:\n    layer.trainable = False\nfor layer in nasnetL3.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:49:52.427574Z","iopub.execute_input":"2023-02-01T05:49:52.428343Z","iopub.status.idle":"2023-02-01T05:49:52.529809Z","shell.execute_reply.started":"2023-02-01T05:49:52.428303Z","shell.execute_reply":"2023-02-01T05:49:52.528737Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"x1 = Flatten()(nasnetL1.output)\nx2 = Flatten()(nasnetL2.output)\nx3 = Flatten()(nasnetL3.output)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:49:56.199262Z","iopub.execute_input":"2023-02-01T05:49:56.199661Z","iopub.status.idle":"2023-02-01T05:49:56.219453Z","shell.execute_reply.started":"2023-02-01T05:49:56.199626Z","shell.execute_reply":"2023-02-01T05:49:56.218393Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"prediction1 = Dense(len(folders), activation='softmax')(x1)\nprediction2 = Dense(len(folders), activation='softmax')(x2)\nprediction3 = Dense(len(folders), activation='softmax')(x3)\nmodel1 = Model(inputs=nasnetL1.input, outputs=prediction1)\nmodel2 = Model(inputs=nasnetL2.input, outputs=prediction2)\nmodel3 = Model(inputs=nasnetL3.input, outputs=prediction3)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:50:00.714710Z","iopub.execute_input":"2023-02-01T05:50:00.715105Z","iopub.status.idle":"2023-02-01T05:50:00.956793Z","shell.execute_reply.started":"2023-02-01T05:50:00.715073Z","shell.execute_reply":"2023-02-01T05:50:00.955587Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model1.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)\nmodel2.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)\nmodel3.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:50:05.518830Z","iopub.execute_input":"2023-02-01T05:50:05.519226Z","iopub.status.idle":"2023-02-01T05:50:05.590752Z","shell.execute_reply.started":"2023-02-01T05:50:05.519192Z","shell.execute_reply":"2023-02-01T05:50:05.589595Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ndata1 = ImageDataGenerator(validation_split = 0.2,\n                          rescale = 1./224,\n                          shear_range = 0.2,\n                          zoom_range = 0.2,\n                          horizontal_flip = True)\ndata2 = ImageDataGenerator(validation_split = 0.2,\n                          rescale = 1./224,\n                          shear_range = 0.2,\n                          zoom_range = 0.2,\n                          horizontal_flip = True)\ndata3 = ImageDataGenerator(validation_split = 0.2,\n                          rescale = 1./224,\n                          shear_range = 0.2,\n                          zoom_range = 0.2,\n                          horizontal_flip = True)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:50:13.567941Z","iopub.execute_input":"2023-02-01T05:50:13.568338Z","iopub.status.idle":"2023-02-01T05:50:13.576472Z","shell.execute_reply.started":"2023-02-01T05:50:13.568306Z","shell.execute_reply":"2023-02-01T05:50:13.575085Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"training_set1 = data1.flow_from_directory(directory=r'../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/',\n                                                 target_size = (331, 331),\n                                                 batch_size = 64,\n                                                 subset = \"training\",\n                                                 class_mode = 'categorical')\ntraining_set2 = data2.flow_from_directory(directory=r'../working/cmyk/',\n                                                 target_size = (331, 331),\n                                                 batch_size = 64,\n                                                 subset = \"training\",\n                                                 class_mode = 'categorical')\ntraining_set3 = data3.flow_from_directory(directory=r'../working/ycbcr/',\n                                                 target_size = (331, 331),\n                                                 batch_size = 64,\n                                                 subset = \"training\",\n                                                 class_mode = 'categorical')","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:50:38.178566Z","iopub.execute_input":"2023-02-01T05:50:38.179295Z","iopub.status.idle":"2023-02-01T05:50:42.296745Z","shell.execute_reply.started":"2023-02-01T05:50:38.179255Z","shell.execute_reply":"2023-02-01T05:50:42.295470Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Found 12000 images belonging to 3 classes.\nFound 12000 images belonging to 3 classes.\nFound 12000 images belonging to 3 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_set1 = data1.flow_from_directory('../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/',\n                                            target_size = (331, 331),\n                                            batch_size = 64,\n                                            subset = \"validation\",\n                                            class_mode = 'categorical')\ntest_set2 = data2.flow_from_directory('../working/cmyk/',\n                                            target_size = (331, 331),\n                                            batch_size = 64,\n                                            subset = \"validation\",\n                                            class_mode = 'categorical')\ntest_set3 = data3.flow_from_directory('../working/ycbcr/',\n                                            target_size = (331, 331),\n                                            batch_size = 64,\n                                            subset = \"validation\",\n                                            class_mode = 'categorical')","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:52:42.107133Z","iopub.execute_input":"2023-02-01T05:52:42.107540Z","iopub.status.idle":"2023-02-01T05:52:45.515517Z","shell.execute_reply.started":"2023-02-01T05:52:42.107504Z","shell.execute_reply":"2023-02-01T05:52:45.513363Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Found 3000 images belonging to 3 classes.\nFound 3000 images belonging to 3 classes.\nFound 3000 images belonging to 3 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"r1 = model1.fit(\n  training_set1,\n  validation_data=test_set1,\n  epochs=15,\n  steps_per_epoch=len(training_set1),\n  validation_steps=len(test_set1)\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T05:53:13.273949Z","iopub.execute_input":"2023-02-01T05:53:13.274433Z","iopub.status.idle":"2023-02-01T08:46:36.365540Z","shell.execute_reply.started":"2023-02-01T05:53:13.274389Z","shell.execute_reply":"2023-02-01T08:46:36.364578Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2023-02-01 05:53:16.629303: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"2023-02-01 05:53:45.227047: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"188/188 [==============================] - 778s 4s/step - loss: 2.1859 - accuracy: 0.9096 - val_loss: 0.9732 - val_accuracy: 0.9530\nEpoch 2/15\n188/188 [==============================] - 703s 4s/step - loss: 1.4208 - accuracy: 0.9474 - val_loss: 2.1353 - val_accuracy: 0.9343\nEpoch 3/15\n188/188 [==============================] - 706s 4s/step - loss: 1.2339 - accuracy: 0.9572 - val_loss: 1.9347 - val_accuracy: 0.9437\nEpoch 4/15\n188/188 [==============================] - 723s 4s/step - loss: 0.9201 - accuracy: 0.9689 - val_loss: 1.0340 - val_accuracy: 0.9613\nEpoch 5/15\n188/188 [==============================] - 714s 4s/step - loss: 0.8792 - accuracy: 0.9699 - val_loss: 1.5504 - val_accuracy: 0.9540\nEpoch 6/15\n188/188 [==============================] - 720s 4s/step - loss: 0.8812 - accuracy: 0.9731 - val_loss: 1.1354 - val_accuracy: 0.9667\nEpoch 7/15\n188/188 [==============================] - 710s 4s/step - loss: 1.1213 - accuracy: 0.9681 - val_loss: 1.3101 - val_accuracy: 0.9643\nEpoch 8/15\n188/188 [==============================] - 697s 4s/step - loss: 0.6123 - accuracy: 0.9807 - val_loss: 1.0637 - val_accuracy: 0.9733\nEpoch 9/15\n188/188 [==============================] - 704s 4s/step - loss: 0.6340 - accuracy: 0.9801 - val_loss: 1.3275 - val_accuracy: 0.9707\nEpoch 10/15\n188/188 [==============================] - 693s 4s/step - loss: 0.8232 - accuracy: 0.9787 - val_loss: 1.2851 - val_accuracy: 0.9717\nEpoch 11/15\n188/188 [==============================] - 651s 3s/step - loss: 0.7136 - accuracy: 0.9808 - val_loss: 1.2471 - val_accuracy: 0.9750\nEpoch 12/15\n188/188 [==============================] - 642s 3s/step - loss: 0.6325 - accuracy: 0.9819 - val_loss: 0.9612 - val_accuracy: 0.9757\nEpoch 13/15\n188/188 [==============================] - 639s 3s/step - loss: 0.5737 - accuracy: 0.9851 - val_loss: 0.7444 - val_accuracy: 0.9817\nEpoch 14/15\n188/188 [==============================] - 641s 3s/step - loss: 0.5558 - accuracy: 0.9853 - val_loss: 1.2898 - val_accuracy: 0.9710\nEpoch 15/15\n188/188 [==============================] - 638s 3s/step - loss: 0.5635 - accuracy: 0.9850 - val_loss: 1.4910 - val_accuracy: 0.9710\n","output_type":"stream"}]},{"cell_type":"code","source":"r2 = model2.fit(\n  training_set2,\n  validation_data=test_set2,\n  epochs=15,\n  steps_per_epoch=len(training_set2),\n  validation_steps=len(test_set2)\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T08:46:36.367647Z","iopub.execute_input":"2023-02-01T08:46:36.368214Z","iopub.status.idle":"2023-02-01T11:42:17.245023Z","shell.execute_reply.started":"2023-02-01T08:46:36.368167Z","shell.execute_reply":"2023-02-01T11:42:17.244031Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch 1/15\n188/188 [==============================] - 740s 4s/step - loss: 2.2067 - accuracy: 0.9079 - val_loss: 1.0374 - val_accuracy: 0.9503\nEpoch 2/15\n188/188 [==============================] - 697s 4s/step - loss: 1.1927 - accuracy: 0.9486 - val_loss: 2.5672 - val_accuracy: 0.9167\nEpoch 3/15\n188/188 [==============================] - 681s 4s/step - loss: 0.9366 - accuracy: 0.9615 - val_loss: 0.9958 - val_accuracy: 0.9557\nEpoch 4/15\n188/188 [==============================] - 702s 4s/step - loss: 1.0925 - accuracy: 0.9625 - val_loss: 1.5629 - val_accuracy: 0.9577\nEpoch 5/15\n188/188 [==============================] - 706s 4s/step - loss: 0.7415 - accuracy: 0.9732 - val_loss: 1.1656 - val_accuracy: 0.9677\nEpoch 6/15\n188/188 [==============================] - 722s 4s/step - loss: 0.6307 - accuracy: 0.9761 - val_loss: 1.2241 - val_accuracy: 0.9653\nEpoch 7/15\n188/188 [==============================] - 718s 4s/step - loss: 0.7640 - accuracy: 0.9764 - val_loss: 1.3724 - val_accuracy: 0.9657\nEpoch 8/15\n188/188 [==============================] - 706s 4s/step - loss: 0.6582 - accuracy: 0.9766 - val_loss: 1.0013 - val_accuracy: 0.9747\nEpoch 9/15\n188/188 [==============================] - 706s 4s/step - loss: 0.7960 - accuracy: 0.9758 - val_loss: 2.1076 - val_accuracy: 0.9533\nEpoch 10/15\n188/188 [==============================] - 704s 4s/step - loss: 0.6875 - accuracy: 0.9801 - val_loss: 0.9975 - val_accuracy: 0.9763\nEpoch 11/15\n188/188 [==============================] - 696s 4s/step - loss: 0.8249 - accuracy: 0.9771 - val_loss: 1.4348 - val_accuracy: 0.9667\nEpoch 12/15\n188/188 [==============================] - 694s 4s/step - loss: 0.7709 - accuracy: 0.9814 - val_loss: 1.2349 - val_accuracy: 0.9727\nEpoch 13/15\n188/188 [==============================] - 705s 4s/step - loss: 0.6591 - accuracy: 0.9825 - val_loss: 1.0714 - val_accuracy: 0.9750\nEpoch 14/15\n188/188 [==============================] - 677s 4s/step - loss: 0.5906 - accuracy: 0.9830 - val_loss: 1.0974 - val_accuracy: 0.9723\nEpoch 15/15\n188/188 [==============================] - 677s 4s/step - loss: 0.6311 - accuracy: 0.9835 - val_loss: 1.0111 - val_accuracy: 0.9787\n","output_type":"stream"}]},{"cell_type":"code","source":"r3 = model3.fit(\n  training_set3,\n  validation_data=test_set3,\n  epochs=15,\n  steps_per_epoch=len(training_set3),\n  validation_steps=len(test_set3)\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T11:42:17.247865Z","iopub.execute_input":"2023-02-01T11:42:17.249001Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/15\n188/188 [==============================] - 659s 3s/step - loss: 1.7453 - accuracy: 0.9151 - val_loss: 1.1373 - val_accuracy: 0.9467\nEpoch 2/15\n188/188 [==============================] - 636s 3s/step - loss: 1.1860 - accuracy: 0.9498 - val_loss: 0.9719 - val_accuracy: 0.9597\nEpoch 3/15\n188/188 [==============================] - 619s 3s/step - loss: 1.2273 - accuracy: 0.9558 - val_loss: 1.9378 - val_accuracy: 0.9480\nEpoch 4/15\n 29/188 [===>..........................] - ETA: 6:55 - loss: 1.0012 - accuracy: 0.9677","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(40,5))\nplt.subplot(1, 5, 1)\nplt.title('RGB')\nplt.plot(r1.history['loss'], label='Train Loss')\nplt.plot(r1.history['val_loss'], label='Val Loss')\nplt.legend()\nplt.subplot(1, 5, 2)\nplt.title('CMYK')\nplt.plot(r2.history['loss'], label='Train Loss')\nplt.plot(r2.history['val_loss'], label='Val Loss')\nplt.legend()\nplt.subplot(1, 5, 3)\nplt.title('YCbCr')\nplt.plot(r3.history['loss'], label='Train Loss')\nplt.plot(r3.history['val_loss'], label='Val Loss')\nplt.legend()\nplt.show()\nplt.figure(figsize=(40,5))\nplt.subplot(1, 5, 1)\nplt.title('RGB')\nplt.plot(r1.history['accuracy'], label='Train Accuracy')\nplt.plot(r1.history['val_accuracy'], label='Val Accuracy')\nplt.legend()\nplt.subplot(1, 5, 2)\nplt.title('CMYK')\nplt.plot(r2.history['accuracy'], label='Train Accuracy')\nplt.plot(r2.history['val_accuracy'], label='Val Accuracy')\nplt.legend()\nplt.subplot(1, 5, 3)\nplt.title('YCbCr')\nplt.plot(r3.history['accuracy'], label='Train Accuracy')\nplt.plot(r3.history['val_accuracy'], label='Val Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel1.save('nasnetlargergb.h5')\nmodel2.save('nasnetlargecmyk.h5')\nmodel3.save('nasnetlargeycbcr.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred1 = model1.predict(test_set1)\ny_pred11 = np.argmax(y_pred1, axis=1)\ny_pred2 = model2.predict(test_set2)\ny_pred22 = np.argmax(y_pred2, axis=1)\ny_pred3 = model3.predict(test_set3)\ny_pred33 = np.argmax(y_pred3, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y1 = test_set1.classes\ny2 = test_set2.classes\ny3 = test_set3.classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder(sparse=False)\ny1 = y1.reshape((3000, 1))\ny_r = encoder.fit_transform(y1)\n\nencoder = OneHotEncoder(sparse=False)\ny2 = y2.reshape((3000, 1))\ny_c = encoder.fit_transform(y2)\n\nencoder = OneHotEncoder(sparse=False)\ny3 = y3.reshape((3000, 1))\ny_y = encoder.fit_transform(y3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = np.concatenate((y_pred1, y_pred2, y_pred3))\ny_label = np.concatenate((y_r, y_c, y_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import neighbors, datasets, preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\nXtrain, Xtest, y_tr, y_test = train_test_split(y_train, y_label, stratify = y_label, random_state = 0, train_size = 0.7)\nprint(y_tr.shape, y_test.shape)\n\n\nknn = neighbors.KNeighborsClassifier(n_neighbors=1)\nknn.fit(Xtrain, y_tr)\ny_pred = knn.predict(Xtest)\n\nprint(accuracy_score(y_test, y_pred, normalize=False))\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\nY_pred1 = model1.predict(test_set1)\ny_pred1 = np.argmax(Y_pred1, axis=1)\nprint(accuracy_score(test_set1.classes, y_pred1))\nprint(classification_report(test_set1.classes, y_pred1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nY_pred2 = model2.predict(test_set2)\ny_pred2 = np.argmax(Y_pred2, axis=1)\nprint(classification_report(test_set2.classes, y_pred2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nY_pred3 = model3.predict(test_set3)\ny_pred3 = np.argmax(Y_pred3, axis=1)\n\nprint(classification_report(test_set3.classes, y_pred3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=True,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, weight='bold', fontsize=16)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, fontsize=14)\n    plt.yticks(tick_marks, classes, fontsize=14)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\", fontsize=12, weight='bold',\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label', fontsize=16, weight='bold')\n    plt.xlabel('Predicted label', fontsize=16, weight='bold')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnf_matrix1 = confusion_matrix(test_set1.classes, y_pred1)\ncnf_matrix2 = confusion_matrix(test_set2.classes, y_pred2)\ncnf_matrix3 = confusion_matrix(test_set3.classes, y_pred3)\nnp.set_printoptions(precision=2)\nplt.figure(figsize=(40,5))\nplt.subplot(1,5,1)\nplt.title('RGB')\nplot_confusion_matrix(cnf_matrix1, classes=['lung_aca', 'lung_n', 'lung_scc'],normalize=True,title='Normalized Confusion Matrix')\nplt.subplot(1,5,2)\nplt.title('CMYK')\nplot_confusion_matrix(cnf_matrix2, classes=['lung_aca', 'lung_n', 'lung_scc'],normalize=True,title='Normalized Confusion Matrix')\nplt.subplot(1,5,3)\nplt.title('YCbCr')\nplot_confusion_matrix(cnf_matrix3, classes=['lung_aca', 'lung_n', 'lung_scc'],normalize=True,title='Normalized Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom IPython.display import Image, display\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = (299, 299)\n\nlast_conv_layer_name = \"normal_concat_18\"\nimg_rgb = \"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_n/lungn4125.jpeg\"\nimg_cmyk = \"../working/cmyk/lung_n/lungn3988.jpeg\"\nimg_ycbcr = \"../working/cmyk/lung_n/lungn3988.jpeg\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_array(img_path, size):\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    array = keras.preprocessing.image.img_to_array(img)\n    # of size (1, 299, 299, 3)\n    array = np.expand_dims(array, axis=0)\n    return array\n\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_rgb_array = preprocess_input(get_img_array(img_rgb, size=img_size))\nimg_cmyk_array = preprocess_input(get_img_array(img_cmyk, size=img_size))\nimg_ycbcr_array = preprocess_input(get_img_array(img_ycbcr, size=img_size))\n\n# Make model\nmodel_rgb = keras.model.load_model('nasnetlargergb.h5')\nmodel_cmyk = keras.model.load_model('nasnetlargecmyk.h5')\nmodel_ycbcr = keras.model.load_model('nasnetlargeycbcr.h5')\n\n\n# Remove last layer's softmax\nmodel_rgb.layers[-1].activation = None\nmodel_cmyk.layers[-1].activation = None\nmodel_ycbcr.layers[-1].activation = None\n\n# Print what the top predicted class is\npreds_rgb = model_rgb.predict(img_rgb_array)\npreds_cmyk = model_rgb.predict(img_cmyk_array)\npreds_ycbcr = model_rgb.predict(img_ycbcr_array)\nprint(\"Predicted:\", decode_predictions(preds_rgb, top=1)[0])\nprint(\"Predicted:\", decode_predictions(preds_cmyk, top=1)[0])\nprint(\"Predicted:\", decode_predictions(preds_ycbcr, top=1)[0])\nheatmap_rgb = make_gradcam_heatmap(img_rgb, model, last_conv_layer_name)\nplt.matshow(heatmap_rgb)\nheatmap_cmyk = make_gradcam_heatmap(img_cmyk, model, last_conv_layer_name)\nplt.matshow(heatmap_cmyk)\nheatmap_ycbcr = make_gradcam_heatmap(img_ycbcr, model, last_conv_layer_name)\nplt.matshow(heatmap_ycbcr)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n    img = keras.preprocessing.image.load_img(img_path)\n    img = keras.preprocessing.image.img_to_array(img)\n    heatmap = np.uint8(255 * heatmap)\n    jet = cm.get_cmap(\"jet\")\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n    superimposed_img.save(cam_path)\n    display(Image(cam_path))\n    \n\nsave_and_display_gradcam(img_rgb, heatmap_rgb)\nsave_and_display_gradcam(img_cmyk, heatmap_cmyk)\nsave_and_display_gradcam(img_ycbcr, heatmap_ycbcr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}